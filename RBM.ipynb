{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI0CfTdl2o08sHZX6JHcq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salma-Kassem/DeepLearning/blob/main/RBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uymf0EgUuwvi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize to [0, 1]\n",
        "x_train = x_train.astype(np.float32) / 255.\n",
        "x_test = x_test.astype(np.float32) / 255.\n",
        "\n",
        "# Flatten images for RBM input (28*28=784)\n",
        "x_train_flat = x_train.reshape(-1, 784)\n",
        "x_test_flat = x_test.reshape(-1, 784)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pick an example image\n",
        "index = 0\n",
        "image = x_train[index]  # shape: (28, 28)\n",
        "label = y_train[index]\n",
        "\n",
        "# Display\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.axis('off')  # hides the axis for clarity\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "a5gj4YYKyJ7D",
        "outputId": "cb96447f-06cd-4181-d9ee-f0abbb490fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RBM clas**"
      ],
      "metadata": {
        "id": "y1ZvFyQvwFN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(probabilities, mode='bernoulli'):\n",
        "    ''' Sample a tensor based on the probabilities (A tensor given by get_probabilities)'''\n",
        "    if mode=='bernoulli':\n",
        "        return tf.floor(probabilities + tf.random.uniform(tf.shape(probabilities), 0, 1))\n",
        "    elif mode=='gaussian':\n",
        "        return tf.add(probabilities, tf.random.normal(tf.shape(probabilities), mean=0.0, stddev=1.)) # Add noise to the original probabilities\n",
        "\n",
        "\n",
        "\n",
        "# Simple RBM class\n",
        "class RBM:\n",
        "\n",
        "    def __init__(self, n_visible, n_hidden, lr, epochs, mode='bernoulli'):\n",
        "        ''' Initialize a model for an RBM with one layer of hidden units '''\n",
        "        self.mode = mode # bernoulli or gaussian RBM\n",
        "        self.n_hidden = n_hidden #  Number of hidden nodes\n",
        "        self.n_visible = n_visible # Number of visible nodes\n",
        "        self.lr = lr # Learning rate for the CD algorithm\n",
        "        self.epochs = epochs # Number of iterations to run the algorithm for\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        with tf.name_scope('Weights'):\n",
        "            self.W = tf.Variable(tf.random.normal([self.n_visible, self.n_hidden], mean=0., stddev=4 * np.sqrt(6. / (self.n_visible + self.n_hidden))), name=\"weights\")\n",
        "        self.vb = tf.Variable(tf.zeros([1, self.n_visible]),tf.float32, name=\"visible_bias\")\n",
        "        self.hb = tf.Variable(tf.zeros([1, self.n_hidden]),tf.float32, name=\"hidden_bias\")\n",
        "\n",
        "\n",
        "    def get_probabilities(self, layer, val):\n",
        "        ''' Return a tensor of probabilities associated with the layer specified'''\n",
        "        if layer == 'hidden':\n",
        "            with tf.name_scope(\"Hidden_Probabilities\"):\n",
        "                if self.mode=='bernoulli':\n",
        "                    return tf.nn.sigmoid(tf.matmul(val, self.W) + self.hb)\n",
        "                elif self.mode=='gaussian':\n",
        "                    return tf.matmul(val, self.W) + self.hb\n",
        "\n",
        "        elif layer == 'visible':\n",
        "            with tf.name_scope(\"Visible_Probabilities\"):\n",
        "                return tf.nn.sigmoid(tf.matmul(val, tf.transpose(self.W)) + self.vb)\n",
        "\n",
        "\n",
        "    def CD(self, v, K=1):\n",
        "        ''' K-step Contrastive Divergence using Gibbs sampling. Return parameters update. '''\n",
        "        with tf.name_scope(\"Contrastive_Divergence\"):\n",
        "            h_prob = self.get_probabilities('hidden', v)\n",
        "            h_state = sample(h_prob, mode=self.mode)\n",
        "            pos_divergence = tf.matmul(tf.transpose(v), h_prob) # Positive Divergence + h(v).v^T\n",
        "\n",
        "            fake_v_prob = self.get_probabilities('visible', h_state)\n",
        "            fake_v_state = fake_v_prob #sample(fake_v_prob)\n",
        "\n",
        "            fake_h_prob = self.get_probabilities('hidden', fake_v_state)\n",
        "            fake_h_state = sample(fake_h_prob, mode=self.mode)\n",
        "\n",
        "            for i in range(K-1): # Number of steps to run the algorithm\n",
        "\n",
        "                fake_v_prob = self.get_probabilities('visible', fake_h_state)\n",
        "                fake_v_state = fake_v_prob #sample(fake_v_prob)\n",
        "\n",
        "                fake_h_prob = self.get_probabilities('hidden', fake_v_state)\n",
        "                fake_h_state = sample(fake_h_prob, mode=self.mode)\n",
        "\n",
        "            neg_divergence = tf.matmul(tf.transpose(fake_v_state), fake_h_prob) # Negative Divergence - h(v').v'^T\n",
        "\n",
        "            dW = pos_divergence-neg_divergence\n",
        "            dvb = v-fake_v_state\n",
        "            dhb = h_prob-fake_h_prob\n",
        "\n",
        "            # Similarity between reconstructed visible layer and input during training.\n",
        "            self.rec_error = tf.reduce_mean(tf.math.squared_difference(v, fake_v_state))\n",
        "\n",
        "\n",
        "            self.div = tf.reduce_mean(tf.abs(dW))\n",
        "\n",
        "            return dW, dvb, dhb\n",
        "\n",
        "\n",
        "    def update(self, v, K=1):\n",
        "        batch_size = tf.cast(tf.shape(v)[0], tf.float32) # batch size\n",
        "        dW, dvb, dhb = self.CD(v, K=K) # contrastive divergence\n",
        "\n",
        "        delta_w = (self.lr/batch_size)*dW # weight gradient\n",
        "        delta_vb = (self.lr/batch_size)*(tf.reduce_sum(dvb, 0, keepdims =True)) # visible bias gradient\n",
        "        delta_hb = (self.lr/batch_size)*(tf.reduce_sum(dhb, 0, keepdims =True)) # hidden bias gradient\n",
        "\n",
        "        train_op = [self.W.assign_add(delta_w), self.vb.assign_add(delta_vb), self.hb.assign_add(delta_hb)]\n",
        "        return train_op\n",
        "\n",
        "\n",
        "    def gibbs(self, steps, v):\n",
        "        ''' Use the Gibbs sampler for a network of hidden and visible units. Return a sampled version of the input'''\n",
        "        with tf.name_scope(\"Gibbs_sampling\"):\n",
        "            for i in range(steps): # Number of steps to run the algorithm\n",
        "                hidden_p = self.get_probabilities('hidden', v) # v: input data\n",
        "                h = sample(hidden_p, mode=self.mode)\n",
        "\n",
        "                visible_p = self.get_probabilities('visible', h)\n",
        "                v = visible_p\n",
        "                #v = sample(visible_p)\n",
        "            return visible_p\n",
        "\n",
        "\n",
        "    def get_feature_map(self):\n",
        "        ''' Return hidden features'''\n",
        "        ft_map = {}\n",
        "        for k in range(self.n_hidden):\n",
        "            ft_map[k] = self.get_probabilities('visible', tf.expand_dims(tf.one_hot(k+1, self.n_hidden),0))\n",
        "        return ft_map\n",
        "\n",
        "    def transform(self, X):\n",
        "        ''' Return the hidden layer probabilities (latent features) for input X '''\n",
        "        return self.get_probabilities('hidden', X)\n",
        "\n"
      ],
      "metadata": {
        "id": "dLHgfY8vv_Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title(f\"Label: {y_train[0]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DXdn6ftV8unz",
        "outputId": "f0a5e396-e092-40b8-b1ad-022689ee4d4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **initialize**"
      ],
      "metadata": {
        "id": "bkPBS-u3wKJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rbm = RBM(n_visible=784, n_hidden=128, lr=0.01, epochs=15, mode='bernoulli')\n",
        "\n",
        "batch_size = 64\n",
        "num_batches = x_train_flat.shape[0] // batch_size\n",
        "for epoch in range(rbm.epochs):\n",
        "    perm = np.random.permutation(x_train_flat.shape[0])\n",
        "    x_train_shuffled = x_train_flat[perm]\n",
        "    epoch_loss = []\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        batch = x_train_shuffled[i*batch_size:(i+1)*batch_size]\n",
        "        train_ops = rbm.update(batch, K=1)\n",
        "        # Run the train ops inside a TF session/eager\n",
        "        tf.keras.backend.batch_get_value(train_ops)  # Execute the assignments\n",
        "        epoch_loss.append(rbm.rec_error.numpy())\n",
        "    print(f\"Epoch {epoch+1}/{rbm.epochs}, Reconstruction error: {np.mean(epoch_loss):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFs6SBNbuzQ5",
        "outputId": "ce4b402c-aad4-4e00-bb78-5e62ae91a9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Reconstruction error: 0.0694\n",
            "Epoch 2/15, Reconstruction error: 0.0519\n",
            "Epoch 3/15, Reconstruction error: 0.0485\n",
            "Epoch 4/15, Reconstruction error: 0.0465\n",
            "Epoch 5/15, Reconstruction error: 0.0451\n",
            "Epoch 6/15, Reconstruction error: 0.0441\n",
            "Epoch 7/15, Reconstruction error: 0.0433\n",
            "Epoch 8/15, Reconstruction error: 0.0427\n",
            "Epoch 9/15, Reconstruction error: 0.0421\n",
            "Epoch 10/15, Reconstruction error: 0.0416\n",
            "Epoch 11/15, Reconstruction error: 0.0412\n",
            "Epoch 12/15, Reconstruction error: 0.0408\n",
            "Epoch 13/15, Reconstruction error: 0.0404\n",
            "Epoch 14/15, Reconstruction error: 0.0401\n",
            "Epoch 15/15, Reconstruction error: 0.0398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = rbm.transform(x_train_flat).numpy()\n",
        "test_features = rbm.transform(x_test_flat).numpy()"
      ],
      "metadata": {
        "id": "LpgFM_Zg48Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "mlp = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(rbm.n_hidden,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "mlp.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "mlp.fit(train_features, y_train_cat, epochs=20, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYnVZv8t3ulP",
        "outputId": "f0da54ee-0c6d-4293-9267-116476805a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6299 - loss: 1.0912 - val_accuracy: 0.7375 - val_loss: 0.6395\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.6406 - val_accuracy: 0.7523 - val_loss: 0.6063\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.6132 - val_accuracy: 0.7535 - val_loss: 0.5977\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.5964 - val_accuracy: 0.7562 - val_loss: 0.5909\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7579 - loss: 0.5822 - val_accuracy: 0.7573 - val_loss: 0.5860\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7533 - loss: 0.5815 - val_accuracy: 0.7597 - val_loss: 0.5755\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7583 - loss: 0.5783 - val_accuracy: 0.7603 - val_loss: 0.5718\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7586 - loss: 0.5735 - val_accuracy: 0.7622 - val_loss: 0.5704\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7624 - loss: 0.5575 - val_accuracy: 0.7645 - val_loss: 0.5671\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.5657 - val_accuracy: 0.7632 - val_loss: 0.5689\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.5597 - val_accuracy: 0.7627 - val_loss: 0.5693\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7697 - loss: 0.5511 - val_accuracy: 0.7630 - val_loss: 0.5672\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7700 - loss: 0.5431 - val_accuracy: 0.7663 - val_loss: 0.5598\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7711 - loss: 0.5459 - val_accuracy: 0.7672 - val_loss: 0.5546\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.5448 - val_accuracy: 0.7655 - val_loss: 0.5643\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.5427 - val_accuracy: 0.7618 - val_loss: 0.5679\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.5413 - val_accuracy: 0.7717 - val_loss: 0.5551\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7726 - loss: 0.5408 - val_accuracy: 0.7665 - val_loss: 0.5521\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.5447 - val_accuracy: 0.7583 - val_loss: 0.5591\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.5343 - val_accuracy: 0.7590 - val_loss: 0.5534\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1432967510>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build MLP classifier using raw images\n",
        "mlp_raw = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "mlp_raw.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Train the MLP on raw images\n",
        "mlp_raw.fit(x_train_flat, y_train_cat, epochs=20, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate on test images\n",
        "test_loss_raw, test_acc_raw = mlp_raw.evaluate(x_test_flat, y_test_cat)\n",
        "print(f\"Test accuracy on raw images: {test_acc_raw:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z6c38Dm0KFv",
        "outputId": "21fad686-9ca9-4280-a36c-fd027f53fac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.7674 - loss: 0.6550 - val_accuracy: 0.8605 - val_loss: 0.3851\n",
            "Epoch 2/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8621 - loss: 0.3803 - val_accuracy: 0.8713 - val_loss: 0.3582\n",
            "Epoch 3/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8758 - loss: 0.3386 - val_accuracy: 0.8618 - val_loss: 0.3939\n",
            "Epoch 4/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.3129 - val_accuracy: 0.8782 - val_loss: 0.3333\n",
            "Epoch 5/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8925 - loss: 0.2878 - val_accuracy: 0.8797 - val_loss: 0.3364\n",
            "Epoch 6/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9003 - loss: 0.2715 - val_accuracy: 0.8752 - val_loss: 0.3408\n",
            "Epoch 7/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9037 - loss: 0.2614 - val_accuracy: 0.8800 - val_loss: 0.3313\n",
            "Epoch 8/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9051 - loss: 0.2541 - val_accuracy: 0.8875 - val_loss: 0.3159\n",
            "Epoch 9/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9090 - loss: 0.2404 - val_accuracy: 0.8895 - val_loss: 0.3038\n",
            "Epoch 10/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2332 - val_accuracy: 0.8835 - val_loss: 0.3414\n",
            "Epoch 11/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9187 - loss: 0.2162 - val_accuracy: 0.8838 - val_loss: 0.3393\n",
            "Epoch 12/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9187 - loss: 0.2140 - val_accuracy: 0.8897 - val_loss: 0.3246\n",
            "Epoch 13/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9236 - loss: 0.2032 - val_accuracy: 0.8897 - val_loss: 0.3496\n",
            "Epoch 14/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9254 - loss: 0.1987 - val_accuracy: 0.8930 - val_loss: 0.3343\n",
            "Epoch 15/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.9276 - loss: 0.1913 - val_accuracy: 0.8938 - val_loss: 0.3229\n",
            "Epoch 16/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9301 - loss: 0.1814 - val_accuracy: 0.8923 - val_loss: 0.3386\n",
            "Epoch 17/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.1751 - val_accuracy: 0.8917 - val_loss: 0.3639\n",
            "Epoch 18/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9341 - loss: 0.1737 - val_accuracy: 0.8955 - val_loss: 0.3266\n",
            "Epoch 19/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9371 - loss: 0.1654 - val_accuracy: 0.8912 - val_loss: 0.3433\n",
            "Epoch 20/20\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9396 - loss: 0.1600 - val_accuracy: 0.8962 - val_loss: 0.3431\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3762\n",
            "Test accuracy on raw images: 0.8927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate MLP on RBM features\n",
        "loss_rbm, acc_rbm = mlp.evaluate(test_features, y_test_cat, verbose=0)\n",
        "print(f\"MLP on RBM features - Test Loss: {loss_rbm:.4f}, Test Accuracy: {acc_rbm:.4f}\")\n",
        "\n",
        "# Evaluate MLP on raw images\n",
        "loss_raw, acc_raw = mlp_raw.evaluate(x_test_flat, y_test_cat, verbose=0)\n",
        "print(f\"MLP on raw images - Test Loss: {loss_raw:.4f}, Test Accuracy: {acc_raw:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg3upDR40dTA",
        "outputId": "8f2179ab-45f9-4a49-f2e2-1d90225642a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP on RBM features - Test Loss: 0.5932, Test Accuracy: 0.7546\n",
            "MLP on raw images - Test Loss: 0.3696, Test Accuracy: 0.8927\n"
          ]
        }
      ]
    }
  ]
}